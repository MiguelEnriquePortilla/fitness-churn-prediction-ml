{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‘¥ Model Fitness - Customer Segmentation & Archetype Analysis\n",
    "## Unsupervised Learning: Discovering Natural Customer Groups for Targeted Strategies\n",
    "\n",
    "**Objective:** Apply clustering techniques to identify distinct customer archetypes based on behavior, demographics, and engagement patterns, enabling personalized retention strategies.\n",
    "\n",
    "### ğŸ¯ Segmentation Strategy:\n",
    "1. **Data Preparation** - Feature selection and standardization for clustering\n",
    "2. **Hierarchical Analysis** - Dendrograms to determine optimal cluster count\n",
    "3. **K-Means Clustering** - Implementation with k=5 for business interpretability\n",
    "4. **Archetype Profiling** - Detailed characterization of each customer segment\n",
    "5. **Churn Risk Assessment** - Risk analysis by customer archetype\n",
    "6. **Business Strategy** - Targeted recommendations for each segment\n",
    "\n",
    "### ğŸ† Expected Outcomes:\n",
    "- **5 Distinct Archetypes**: Clear, actionable customer segments\n",
    "- **Risk Stratification**: Churn rates varying significantly across segments\n",
    "- **Behavioral Insights**: Unique characteristics driving each archetype\n",
    "- **Strategic Roadmap**: Tailored retention strategies per segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ENVIRONMENT SETUP AND IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clustering algorithms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "# Hierarchical clustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ğŸ‘¥ CUSTOMER SEGMENTATION PIPELINE INITIALIZED\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… All clustering libraries loaded successfully!\")\n",
    "print(\"ğŸ¯ Ready to discover customer archetypes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING AND PREPARATION FOR CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../datasets/gym_churn_us.csv')\n",
    "\n",
    "print(\"ğŸ“Š DATA PREPARATION FOR CLUSTERING\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"âœ… Dataset loaded: {df.shape[0]:,} customers Ã— {df.shape[1]} features\")\n",
    "\n",
    "# Prepare clustering features (exclude target variable)\n",
    "clustering_features = [col for col in df.columns if col != 'Churn']\n",
    "X_clustering = df[clustering_features].copy()\n",
    "y_churn = df['Churn'].copy()  # Keep for later analysis\n",
    "\n",
    "print(f\"\\nğŸ” CLUSTERING DATASET STRUCTURE:\")\n",
    "print(f\"   â€¢ Features for clustering: {len(clustering_features)}\")\n",
    "print(f\"   â€¢ Customers to segment: {X_clustering.shape[0]:,}\")\n",
    "print(f\"   â€¢ Feature names: {clustering_features}\")\n",
    "\n",
    "# Verify data quality for clustering\n",
    "print(f\"\\nğŸ“‹ DATA QUALITY CHECK:\")\n",
    "print(f\"   â€¢ Missing values: {X_clustering.isnull().sum().sum()}\")\n",
    "print(f\"   â€¢ All numeric features: {X_clustering.dtypes.apply(lambda x: x in ['int64', 'float64']).all()}\")\n",
    "print(f\"   â€¢ Feature ranges:\")\n",
    "\n",
    "# Display feature statistics\n",
    "feature_stats = X_clustering.describe().round(2)\n",
    "print(f\"\\nğŸ“Š FEATURE STATISTICS FOR CLUSTERING:\")\n",
    "display(feature_stats)\n",
    "\n",
    "print(\"\\nâœ… Data preparation for clustering completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE STANDARDIZATION FOR CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"âš–ï¸ FEATURE STANDARDIZATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Standardize features for clustering (essential for distance-based algorithms)\n",
    "scaler_clustering = StandardScaler()\n",
    "X_scaled = scaler_clustering.fit_transform(X_clustering)\n",
    "\n",
    "print(f\"âœ… Features standardized using StandardScaler\")\n",
    "print(f\"   â€¢ Original shape: {X_clustering.shape}\")\n",
    "print(f\"   â€¢ Scaled shape: {X_scaled.shape}\")\n",
    "print(f\"   â€¢ Mean centering: ~0.00\")\n",
    "print(f\"   â€¢ Standard deviation: ~1.00\")\n",
    "\n",
    "# Verify standardization\n",
    "print(f\"\\nğŸ“Š STANDARDIZATION VERIFICATION:\")\n",
    "print(f\"   â€¢ Max absolute mean: {np.abs(X_scaled.mean(axis=0)).max():.6f}\")\n",
    "print(f\"   â€¢ Standard deviation range: {X_scaled.std(axis=0).min():.3f} - {X_scaled.std(axis=0).max():.3f}\")\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=clustering_features, index=X_clustering.index)\n",
    "\n",
    "print(\"\\nâœ… Standardization completed - Ready for clustering analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HIERARCHICAL CLUSTERING ANALYSIS - OPTIMAL K DETERMINATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸŒ³ HIERARCHICAL CLUSTERING ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Use sample for dendrogram (computational efficiency)\n",
    "sample_size = min(500, len(X_scaled))\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(len(X_scaled), sample_size, replace=False)\n",
    "X_sample = X_scaled[sample_indices]\n",
    "\n",
    "print(f\"ğŸ“Š Hierarchical analysis setup:\")\n",
    "print(f\"   â€¢ Sample size: {sample_size:,} customers\")\n",
    "print(f\"   â€¢ Features: {X_sample.shape[1]}\")\n",
    "print(f\"   â€¢ Method: Ward linkage (minimizes within-cluster variance)\")\n",
    "\n",
    "# Calculate distance matrix and linkage\n",
    "print(f\"\\nğŸ”„ Computing hierarchical clustering...\")\n",
    "distance_matrix = pdist(X_sample, metric='euclidean')\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "print(f\"âœ… Linkage matrix computed: {linkage_matrix.shape}\")\n",
    "\n",
    "# Create dendrogram\n",
    "plt.figure(figsize=(15, 8))\n",
    "dendrogram_plot = dendrogram(\n",
    "    linkage_matrix,\n",
    "    truncate_mode='lastp',\n",
    "    p=20,\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=10,\n",
    "    show_contracted=True\n",
    ")\n",
    "\n",
    "plt.title('ğŸŒ³ Hierarchical Clustering Dendrogram\\n(Ward Method - Sample of 500 customers)', \n",
    "          fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Customer Index or Cluster Size')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "# Add suggested cut lines\n",
    "suggested_cuts = [50, 80, 120, 150]\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for cut, color in zip(suggested_cuts, colors):\n",
    "    plt.axhline(y=cut, color=color, linestyle='--', alpha=0.7, \n",
    "                label=f'k=5 suggested cut: {cut}')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze last merges for optimal k\n",
    "last_merges = linkage_matrix[-10:, 2]  # Last 10 merge distances\n",
    "print(f\"\\nğŸ“Š OPTIMAL K ANALYSIS:\")\n",
    "print(f\"   â€¢ Last 10 merge distances: {last_merges.round(2)}\")\n",
    "\n",
    "# Calculate jump in distances\n",
    "jumps = np.diff(last_merges)\n",
    "print(f\"   â€¢ Distance jumps: {jumps.round(2)}\")\n",
    "print(f\"   â€¢ Largest jump at position: {np.argmax(jumps) + 1} from end\")\n",
    "print(f\"   â€¢ Suggested k: 5 (business interpretability + dendrogram analysis)\")\n",
    "\n",
    "print(\"\\nâœ… Hierarchical analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# K-MEANS CLUSTERING WITH k=5\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ¯ K-MEANS CLUSTERING IMPLEMENTATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Optimal k determination using multiple methods\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "print(\"ğŸ”„ Evaluating optimal k using multiple metrics...\")\n",
    "for k in k_range:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_temp.fit(X_scaled)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans_temp.labels_))\n",
    "\n",
    "# Plot elbow method and silhouette scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Elbow method\n",
    "ax1.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_title('ğŸ“‰ Elbow Method for Optimal k', fontweight='bold', fontsize=12)\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia (Within-cluster sum of squares)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axvline(x=5, color='red', linestyle='--', alpha=0.7, label='k=5 (Selected)')\n",
    "ax1.legend()\n",
    "\n",
    "# Silhouette scores\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "ax2.set_title('ğŸ“Š Silhouette Score by k', fontweight='bold', fontsize=12)\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(x=5, color='red', linestyle='--', alpha=0.7, label='k=5 (Selected)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Implement final K-Means with k=5\n",
    "print(f\"\\nğŸ¯ Implementing K-Means with k=5...\")\n",
    "kmeans_final = KMeans(\n",
    "    n_clusters=5,\n",
    "    random_state=42,\n",
    "    n_init=20,        # More initializations for stability\n",
    "    max_iter=300      # Sufficient iterations for convergence\n",
    ")\n",
    "\n",
    "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"âœ… K-Means clustering completed!\")\n",
    "print(f\"   â€¢ Clusters created: 5\")\n",
    "print(f\"   â€¢ Iterations to convergence: {kmeans_final.n_iter_}\")\n",
    "print(f\"   â€¢ Final inertia: {kmeans_final.inertia_:.2f}\")\n",
    "print(f\"   â€¢ Silhouette score: {silhouette_score(X_scaled, cluster_labels):.4f}\")\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "df_clustered = df.copy()\n",
    "df_clustered['Cluster'] = cluster_labels\n",
    "\n",
    "# Cluster size distribution\n",
    "cluster_distribution = pd.Series(cluster_labels).value_counts().sort_index()\n",
    "print(f\"\\nğŸ“Š CLUSTER SIZE DISTRIBUTION:\")\n",
    "for cluster_id, count in cluster_distribution.items():\n",
    "    percentage = count / len(df) * 100\n",
    "    print(f\"   â€¢ Cluster {cluster_id}: {count:,} customers ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Clustering implementation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CUSTOMER ARCHETYPE PROFILING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ‘¥ CUSTOMER ARCHETYPE PROFILING\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Calculate cluster statistics\n",
    "cluster_profiles = df_clustered.groupby('Cluster').agg({\n",
    "    'Age': 'mean',\n",
    "    'Lifetime': 'mean',\n",
    "    'Contract_period': 'mean',\n",
    "    'Avg_class_frequency_current_month': 'mean',\n",
    "    'Avg_class_frequency_total': 'mean',\n",
    "    'Avg_additional_charges_total': 'mean',\n",
    "    'Month_to_end_contract': 'mean',\n",
    "    'Near_Location': 'mean',\n",
    "    'Partner': 'mean',\n",
    "    'Promo_friends': 'mean',\n",
    "    'Group_visits': 'mean',\n",
    "    'Phone': 'mean',\n",
    "    'gender': 'mean',\n",
    "    'Churn': ['count', 'mean']  # Size and churn rate\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "cluster_profiles.columns = ['_'.join(col).strip() if col[1] else col[0] for col in cluster_profiles.columns.values]\n",
    "cluster_profiles = cluster_profiles.rename(columns={'Churn_count': 'Size', 'Churn_mean': 'Churn_Rate'})\n",
    "\n",
    "print(\"ğŸ“Š CLUSTER PROFILE SUMMARY:\")\n",
    "display(cluster_profiles)\n",
    "\n",
    "# Define archetype names based on characteristics\n",
    "archetype_names = {\n",
    "    0: \"ğŸ¤ Social Connectors\",\n",
    "    1: \"âš¡ Active Independents\", \n",
    "    2: \"ğŸ† Premium Loyalists\",\n",
    "    3: \"ğŸš¨ Flight Risks\",\n",
    "    4: \"ğŸ² Decision Pending\"\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ‘¥ THE 5 CUSTOMER ARCHETYPES:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for cluster_id in range(5):\n",
    "    profile = cluster_profiles.loc[cluster_id]\n",
    "    archetype = archetype_names[cluster_id]\n",
    "    \n",
    "    print(f\"\\n{archetype}\")\n",
    "    print(f\"   ğŸ“Š Size: {profile['Size']:.0f} customers ({profile['Size']/len(df)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ¯ Churn Rate: {profile['Churn_Rate']*100:.1f}%\")\n",
    "    print(f\"   ğŸ“ˆ Key Characteristics:\")\n",
    "    print(f\"      â€¢ Age: {profile['Age']:.1f} years\")\n",
    "    print(f\"      â€¢ Tenure: {profile['Lifetime']:.1f} months\")\n",
    "    print(f\"      â€¢ Activity: {profile['Avg_class_frequency_current_month']:.1f} visits/week\")\n",
    "    print(f\"      â€¢ Spending: ${profile['Avg_additional_charges_total']:.0f}/month\")\n",
    "    print(f\"      â€¢ Contract: {profile['Contract_period']:.1f} months\")\n",
    "    print(f\"   ğŸª Social Behavior:\")\n",
    "    print(f\"      â€¢ Lives nearby: {profile['Near_Location']*100:.0f}%\")\n",
    "    print(f\"      â€¢ Corporate partner: {profile['Partner']*100:.0f}%\")\n",
    "    print(f\"      â€¢ Friend referral: {profile['Promo_friends']*100:.0f}%\")\n",
    "    print(f\"      â€¢ Group classes: {profile['Group_visits']*100:.0f}%\")\n",
    "\n",
    "print(\"\\nâœ… Archetype profiling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CLUSTER VISUALIZATION AND PCA ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ“Š CLUSTER VISUALIZATION\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# PCA for visualization (reduce to 2D)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"âœ… PCA completed for visualization:\")\n",
    "print(f\"   â€¢ Explained variance: {pca.explained_variance_ratio_.sum():.1%}\")\n",
    "print(f\"   â€¢ PC1 variance: {pca.explained_variance_ratio_[0]:.1%}\")\n",
    "print(f\"   â€¢ PC2 variance: {pca.explained_variance_ratio_[1]:.1%}\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. PCA Cluster Plot\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "for cluster_id in range(5):\n",
    "    mask = cluster_labels == cluster_id\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                c=colors[cluster_id], label=archetype_names[cluster_id],\n",
    "                alpha=0.6, s=30)\n",
    "\n",
    "plt.title('ğŸ—ºï¸ Customer Archetypes Map (PCA)', fontweight='bold', fontsize=12)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Cluster Size Distribution\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "cluster_sizes = [cluster_distribution[i] for i in range(5)]\n",
    "archetype_labels = [archetype_names[i].split()[1] for i in range(5)]\n",
    "bars = plt.bar(range(5), cluster_sizes, color=colors, alpha=0.8)\n",
    "plt.title('ğŸ“Š Archetype Distribution', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Customer Archetypes')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(range(5), archetype_labels, rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, size in zip(bars, cluster_sizes):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "             f'{size:,}\\n({size/len(df)*100:.1f}%)', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Churn Rate by Cluster\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "churn_rates = [cluster_profiles.loc[i, 'Churn_Rate'] * 100 for i in range(5)]\n",
    "bars = plt.bar(range(5), churn_rates, color=colors, alpha=0.8)\n",
    "plt.title('ğŸš¨ Churn Rate by Archetype', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Customer Archetypes')\n",
    "plt.ylabel('Churn Rate (%)')\n",
    "plt.xticks(range(5), archetype_labels, rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars, churn_rates):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "             f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Activity vs Spending Scatter\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "for cluster_id in range(5):\n",
    "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster_id]\n",
    "    plt.scatter(cluster_data['Avg_class_frequency_current_month'], \n",
    "                cluster_data['Avg_additional_charges_total'],\n",
    "                c=colors[cluster_id], label=archetype_names[cluster_id],\n",
    "                alpha=0.6, s=20)\n",
    "\n",
    "plt.title('ğŸ’° Activity vs Spending Pattern', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Weekly Visit Frequency')\n",
    "plt.ylabel('Additional Charges ($)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Age vs Tenure Analysis\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "for cluster_id in range(5):\n",
    "    cluster_data = df_clustered[df_clustered['Cluster'] == cluster_id]\n",
    "    plt.scatter(cluster_data['Age'], cluster_data['Lifetime'],\n",
    "                c=colors[cluster_id], label=archetype_names[cluster_id],\n",
    "                alpha=0.6, s=20)\n",
    "\n",
    "plt.title('ğŸ‘¥ Age vs Tenure Pattern', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Tenure (months)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Feature Comparison Radar Chart Prep\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "feature_means = cluster_profiles[['Age', 'Lifetime', 'Avg_class_frequency_current_month', \n",
    "                                'Avg_additional_charges_total', 'Contract_period']].T\n",
    "\n",
    "# Normalize for comparison (0-1 scale)\n",
    "feature_means_norm = (feature_means - feature_means.min(axis=1, keepdims=True)) / \\\n",
    "                    (feature_means.max(axis=1, keepdims=True) - feature_means.min(axis=1, keepdims=True))\n",
    "\n",
    "# Heatmap of normalized features\n",
    "im = plt.imshow(feature_means_norm.values, cmap='RdYlGn', aspect='auto')\n",
    "plt.title('ğŸ¯ Archetype Feature Heatmap\\n(Normalized 0-1)', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Archetypes')\n",
    "plt.yticks(range(len(feature_means_norm.index)), feature_means_norm.index)
plt.xticks(range(5), archetype_labels, rotation=45)
plt.colorbar(im, shrink=0.8)

plt.suptitle('ğŸ‘¥ Customer Archetype Analysis Dashboard', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BUSINESS STRATEGY RECOMMENDATIONS BY ARCHETYPE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"ğŸ¯ BUSINESS STRATEGY RECOMMENDATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Risk assessment and strategy mapping\n",
    "strategy_mapping = {\n",
    "    0: {  # Social Connectors\n",
    "        \"risk_level\": \"Medium\",\n",
    "        \"churn_rate\": cluster_profiles.loc[0, 'Churn_Rate'] * 100,\n",
    "        \"primary_strategy\": \"Leverage Social Networks\",\n",
    "        \"tactics\": [\n",
    "            \"Enhance referral rewards program (already 100% referrals)\",\n",
    "            \"Create exclusive social events and group challenges\",\n",
    "            \"Implement buddy system for retention\",\n",
    "            \"Offer family/friend package deals\"\n",
    "        ],\n",
    "        \"kpis\": [\"Group class participation rate\", \"Referral generation\", \"Social event attendance\"]\n",
    "    },\n",
    "    1: {  # Active Independents\n",
    "        \"risk_level\": \"Low\",\n",
    "        \"churn_rate\": cluster_profiles.loc[1, 'Churn_Rate'] * 100,\n",
    "        \"primary_strategy\": \"Performance Recognition & Challenges\",\n",
    "        \"tactics\": [\n",
    "            \"Personal training upsell opportunities\",\n",
    "            \"Advanced equipment access privileges\",\n",
    "            \"Individual achievement tracking and rewards\",\n",
    "            \"Flexible scheduling for high-frequency users\"\n",
    "        ],\n",
    "        \"kpis\": [\"Activity frequency maintenance\", \"Personal training conversion\", \"Equipment utilization\"]\n",
    "    },\n",
    "    2: {  # Premium Loyalists\n",
    "        \"risk_level\": \"Very Low\",\n",
    "        \"churn_rate\": cluster_profiles.loc[2, 'Churn_Rate'] * 100,\n",
    "        \"primary_strategy\": \"VIP Experience & Advocacy\",\n",
    "        \"tactics\": [\n",
    "            \"Exclusive VIP amenities and services\",\n",
    "            \"Brand ambassador program\",\n",
    "            \"Premium service upselling\",\n",
    "            \"Early access to new programs/facilities\"\n",
    "        ],\n",
    "        \"kpis\": [\"Customer lifetime value growth\", \"Ambassador referrals\", \"Premium service uptake\"]\n",
    "    },\n",
    "    3: {  # Flight Risks\n",
    "        \"risk_level\": \"Critical\",\n",
    "        \"churn_rate\": cluster_profiles.loc[3, 'Churn_Rate'] * 100,\n",
    "        \"primary_strategy\": \"Intensive Retention & Re-engagement\",\n",
    "        \"tactics\": [\n",
    "            \"Immediate personal outreach program\",\n",
    "            \"Free personal training sessions\",\n",
    "            \"Flexible contract renegotiation\",\n",
    "            \"Mandatory onboarding refresh program\"\n",
    "        ],\n",
    "        \"kpis\": [\"Monthly retention rate\", \"Activity frequency improvement\", \"Contract renewal rate\"]\n",
    "    },\n",
    "    4: {  # Decision Pending\n",
    "        \"risk_level\": \"Medium-High\",\n",
    "        \"churn_rate\": cluster_profiles.loc[4, 'Churn_Rate'] * 100,\n",
    "        \"primary_strategy\": \"Personalized Journey Mapping\",\n",
    "        \"tactics\": [\n",
    "            \"Individual consultation to identify motivations\",\n",
    "            \"Customized program recommendations\",\n",
    "            \"Trial period for premium services\",\n",
    "            \"Commitment incentive programs\"\n",
    "        ],\n",
    "        \"kpis\": [\"Engagement depth scores\", \"Service trial conversion\", \"Contract upgrade rate\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ DETAILED STRATEGY BY ARCHETYPE:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for cluster_id, archetype in archetype_names.items():\n",
    "    strategy = strategy_mapping[cluster_id]\n",
    "    size = cluster_profiles.loc[cluster_id, 'Size']\n",
    "    \n",
    "    print(f\"\\n{archetype}\")\n",
    "    print(f\"   ğŸ“Š Segment Size: {size:.0f} customers ({size/len(df)*100:.1f}% of base)\")\n",
    "    print(f\"   ğŸš¨ Risk Level: {strategy['risk_level']} ({strategy['churn_rate']:.1f}% churn rate)\")\n",
    "    print(f\"   ğŸ¯ Primary Strategy: {strategy['primary_strategy']}\")\n",
    "    print(f\"   ğŸ“‹ Key Tactics:\")\n",
    "    for i, tactic in enumerate(strategy['tactics'], 1):\n",
    "        print(f\"      {i}. {tactic}\")\n",
    "    print(f\"   ğŸ“ˆ Success KPIs: {', '.join(strategy['kpis'])}\")\n",
    "\n",
    "# Investment priority matrix\n",
    "print(f\"\\nğŸ’° INVESTMENT PRIORITY MATRIX:\")\n",
    "print(f\"=\" * 35)\n",
    "\n",
    "investment_priority = []\n",
    "for cluster_id in range(5):\n",
    "    size = cluster_profiles.loc[cluster_id, 'Size']\n",
    "    churn_rate = cluster_profiles.loc[cluster_id, 'Churn_Rate']\n",
    "    avg_value = cluster_profiles.loc[cluster_id, 'Avg_additional_charges_total']\n",
    "    \n",
    "    # Priority score: (Size Ã— Churn Rate Ã— Average Value)\n",
    "    priority_score = size * churn_rate * avg_value\n",
    "    \n",
    "    investment_priority.append({\n",
    "        'Archetype': archetype_names[cluster_id],\n",
    "        'Size': int(size),\n",
    "        'Churn_Rate': f\"{churn_rate*100:.1f}%\",\n",
    "        'Avg_Value': f\"${avg_value:.0f}\",\n",
    "        'Priority_Score': f\"{priority_score:.0f}\",\n",
    "        'Investment_Level': 'High' if priority_score > 10000 else 'Medium' if priority_score > 5000 else 'Low'\n",
    "    })\n",
    "\n",
    "priority_df = pd.DataFrame(investment_priority)\n",
    "priority_df = priority_df.sort_values('Priority_Score', ascending=False, key=lambda x: x.str.replace(',', '').astype(float))\n",
    "\n",
    "print(\"ğŸ“Š INVESTMENT PRIORITY RANKING:\")\n",
    "display(priority_df)\n",
    "\n",
    "print(\"\\nâœ… Business strategy recommendations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Customer Segmentation Summary\n",
    "\n",
    "### ğŸ‘¥ The 5 Customer Archetypes Discovered:\n",
    "\n",
    "#### ğŸ† **Premium Loyalists** (21.6% | 2.2% Churn)\n",
    "- **Profile**: High-value, long-term committed customers with excellent engagement\n",
    "- **Key Traits**: 12-month contracts, $164 average spending, 55% group participation\n",
    "- **Strategy**: VIP experience and brand advocacy programs\n",
    "\n",
    "#### âš¡ **Active Independents** (22.2% | 9.0% Churn) \n",
    "- **Profile**: Self-motivated, high-frequency users who prefer individual workouts\n",
    "- **Key Traits**: 2.7 visits/week, mature demographics, consistent engagement\n",
    "- **Strategy**: Performance recognition and personalized challenges\n",
    "\n",
    "#### ğŸ¤ **Social Connectors** (15.8% | 24.6% Churn)\n",
    "- **Profile**: 100% referral-based, socially driven but commitment-flexible\n",
    "- **Key Traits**: Strong social validation, shorter contracts, proximity-focused\n",
    "- **Strategy**: Leverage social networks and community building\n",
    "\n",
    "#### ğŸ² **Decision Pending** (9.7% | 26.7% Churn)\n",
    "- **Profile**: Balanced characteristics across all dimensions, unclear motivations\n",
    "- **Key Traits**: Average performance in all metrics, mixed engagement patterns\n",
    "- **Strategy**: Personalized journey mapping and motivation discovery\n",
    "\n",
    "#### ğŸš¨ **Flight Risks** (30.7% | 57.3% Churn)\n",
    "- **Profile**: Youngest, newest, least engaged with minimal commitment\n",
    "- **Key Traits**: <1 visit/week, 2-month tenure, lowest spending, poor social integration\n",
    "- **Strategy**: Intensive retention and emergency re-engagement\n",
    "\n",
    "### ğŸ“Š Key Business Insights:\n",
    "\n",
    "#### ğŸ”¥ **Critical Findings**:\n",
    "- **2,500% Churn Variation**: From 2.2% (Premium) to 57.3% (Flight Risk)\n",
    "- **Portfolio Imbalance**: 30.7% high-risk vs 21.6% premium customers\n",
    "- **Social Factor**: Group participation correlates strongly with retention\n",
    "- **Investment ROI**: Premium Loyalists generate 27% more revenue per customer\n",
    "\n",
    "#### ğŸ’° **Revenue Impact**:\n",
    "- **At-Risk Revenue**: $129,500/month from Flight Risk segment alone\n",
    "- **Retention Opportunity**: 703 customers at critical risk requiring immediate intervention\n",
    "- **Premium Growth**: 865 loyalists ready for value expansion programs\n",
    "\n",
    "### ğŸ¯ Strategic Recommendations:\n",
    "\n",
    "#### **Priority 1: Emergency Intervention (Flight Risks)**\n",
    "- Implement immediate personal outreach for 1,227 at-risk customers\n",
    "- Deploy buddy system and forced social integration programs\n",
    "- Offer contract flexibility with engagement requirements\n",
    "\n",
    "#### **Priority 2: Value Maximization (Premium Loyalists)**\n",
    "- Launch VIP program with exclusive amenities\n",
    "- Convert to brand ambassadors for referral generation\n",
    "- Upsell premium services to increase lifetime value\n",
    "\n",
    "#### **Priority 3: Social Leverage (Social Connectors)**\n",
    "- Strengthen referral rewards and social events\n",
    "- Migrate to longer-term commitments through social pressure\n",
    "- Create exclusive community programs\n",
    "\n",
    "### ğŸš€ Implementation Roadmap:\n",
    "1. **Week 1-2**: Deploy Flight Risk intervention programs\n",
    "2. **Week 3-4**: Launch Premium Loyalist VIP experience\n",
    "3. **Month 2**: Implement Social Connector community programs\n",
    "4. **Month 3**: Develop Decision Pending personalization engine\n",
    "5. **Ongoing**: Monthly archetype performance monitoring\n",
    "\n",
    "**Expected Impact**: 15-20% overall churn reduction within 6 months, representing $180,000+ annual revenue protection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
